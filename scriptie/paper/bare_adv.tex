
%% bare_adv.tex
%% V1.4
%% 2012/12/27
%% by Michael Shell
%% See: 
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the advanced use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8 or later) with an IEEE Computer
%% Society journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex,
%%                    bare_jrnl_transmag.tex
%%*************************************************************************

\documentclass[12pt,journal,compsoc]{IEEEtran}
\newcommand\MYhyperrefoptions{bookmarks=true,bookmarksnumbered=true,
pdfpagemode={UseOutlines},plainpages=false,pdfpagelabels=true,
colorlinks=true,linkcolor={black},citecolor={black},urlcolor={black},
pdftitle={A Comparative Study of Physiological Feature Selection Methods for Emotion Recognition},
pdfsubject={Emotion recognition},
pdfauthor={Andreas De Lille},
pdfkeywords={Emotion recognition, physiological, machine learning, EEG}}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\newcommand{\npar}{\par \vspace{2.3ex plus 0.3ex minus 0.3ex}}

\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
% Do not put math or special symbols in the title.
\title{A Comparative Study of\\ Physiological Feature Selection Methods\\ for Emotion Recognition}
\author{Andreas De Lille}


% The paper headers
\markboth{Extended Abstract, University of Ghent, May 2016}%
{}

\IEEEtitleabstractindextext{%
\begin{abstract}
An emerging topic of research is emotion recognition based on physiological signals and machine learning. Emotion recognition is the process of recognizing a person's emotional state. In this work the emotion recognition was done using a combination of physiological signals and machine learning. The flow of this approach is to record physiological signals from a person, extract features and feed them to a machine learning algorithm. This algorithm will then predict the user's emotional state. Even though a lot of research has been done, there is no agreement on what features are important. This work tries to overcome this problem by comparing a wide range of features with several feature selection methods.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Emotion recognition, physiological signals, machine learning, feature selection methods
\end{IEEEkeywords}}

% make the title area
\maketitle

\IEEEdisplaynontitleabstractindextext
\IEEEpeerreviewmaketitle

\section{Introduction}
\IEEEPARstart{E}{m}otion recognition is the process of recognizing a person's emotion. Observing and recognizing emotion can be done in several ways. Psychology makes a clear distinction between physiological behaviour and a person's expression of emotion. The expression is often prone to social masking, the process of hiding emotion to conform to social standards and ideas, making it less reliable. The physiological behaviour on the other hand is much harder to control, making it more reliable. 

\npar

This work will focus on emotion recognition using physiological signals. Next the classification of emotions will be explained in Section \ref{classification}, before an introduction of physiological signals is given in Section \ref{phyintro}. What follows in Sections \ref{features} and \ref{dataset} is an overview of the used features and the used dataset. The problem statement is given in \ref{} This papers ends with explaining the used approach, results and conclusion of this work. %TODO

\section{classification of emotions}\label{classification}
Before emotion can be recognized, different emotions need to be defined. One way to do this is to use several distinct emotions, e.g. anger, joy, sad and pleasure. The advantage of this approach is that all emotions have a clear label. The disadvantage is that this model is often not complex enough to fully represent an emotion state. To solve this problem, the bipolar valence-arousal model was introduced. This model puts each emotion in a two dimensional space. The first dimension, ranges from inactive to active and indicates how active a person is feeling. The next dimension is valence. This dimension indicates how pleasant or unpleasant the emotion is perceived. 
\npar
The valence-arousal model has the advantage that an emotion can be defined, without needing to explicitly labelling it. Additionally, all discrete emotions can be mapped to the valence-arousal space. For example, excitement corresponds to an active feeling with a pleasant experience, meaning that is will be in the high valence, high arousal quadrant of the space. The mapping of other emotions can be done similarly and is shown in Figure \ref{ArousalValenceModel}.

%TODO \mijnfiguur{width=0.5\textwidth}{ArousalValenceModel}{The arousal - valence model maps emotions in a two dimensional plane\citep{ValArrFig}}

\section{Physiological signals} \label{phyintro}
The emotion recognition will thus take some physiological signals as input and output a valence or arousal score. The 'processing' part is done using machine learning. In short, machine learning is an input output model that predicts output values for different samples based on the inputs. The inputs are features of the input samples, e.g. the frequency or amplitude of a signal.

\npar

To do emotion recognition with machine learning, good features are required. This work focusses on physiological signals that can be split into two groups of features. The first group is are the peripheral signals, a.o. heart rate, blood pressure, respiration rate, perspiration, etc. 

\npar

The second group of features originate from the brain. These signals are recordings of brain activity using electroencephalography (EEG) %TODO gloss. 
EEG is a technique that measures electrical activity of the brain, by placing electrodes on the scalp. Even though EEG is very noisy by nature as the signal is distorted by the bone between the cortex and the electrodes it still provides significant insight in the brain activity. The electrodes are placed according to the 10/20 system, that labels each location. The locations and the corresponding channel names used in this work are visible in Figure \ref{1020labels}.

%\mijnfiguur{width=0.7\textwidth}{1020labels}{Placement of the 32 electrodes in this thesis.}

EEG measures electrical activity at each channel. Each measurement can be split in different frequency bands, with medical relevance. The frequency bands are:
\begin{itemize}
\item \textbf{Alpha:} 8-13Hz, indicate how relaxed and/or inactive the brain is.
\item \textbf{Beta:} 13-30HZ, indicate a more active and focused state of mind.
\item \textbf{Gamma:} 30-50Hz, relate to simultaneous processing of information from different brain areas.
\item \textbf{Delta:} 0-4hz, these waves are generated during dreamless sleep and meditation.
\item \textbf{Theta:} 4-8Hz, occurs during dreaming.
\end{itemize}

%problem statement
\section{Features} \label{features}
\npar
In literature, a lot of features have been found. For the peripheral signals, statistical values of each channel are used. These statistical values are minimum, maximum, variation, standard deviation, average and median of each channel. EEG features use a different approach, here the power spectral density (PSD) of each EEG signal is calculated. The PSD gives the distribution of the signal's energy in the frequency domain. Another power feature is the differential entropy (DE), which is defined as:
\begin{center}
$DE_{channel} = - \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi\sigma^2}} exp(\frac{(x-\mu)^2}{2\sigma^2}) log(\frac{1}{\sqrt{2\pi\sigma^2}}) exp(\frac{(x-\mu)^2}{2\sigma^2})dx$
\end{center}
It is proven that the differential entropy of a certain band is equivalent to the logarithmic power spectral density for a fixed length EEG sequence. This simplifies the calculations significantly.
\begin{center}
$DE_{channel} = log(PSD_{channel})$
\end{center}

\npar

The most used features for valence classification are asymmetry features that measure asymmetry between two channels. This can be done in two ways. The first way is the differential asymmetry (DASM) which is defined as:

\begin{center}
$DASM = DE_{left} - DE_{right}$
\end{center}

Another way to measure the asymmetry is by division. The Rational Asymmetry (RASM) does exactly this and is given by: \\

\begin{center}
$RASM = \frac{DE_{left}}{DE_{right}}$
\end{center}

\npar

The asymmetry features can also be used in the other direction. Instead of looking at the asymmetry between left and right, one can also compare the frontal power with the posterior power. This is known as the caudality. The differential caudality (DCAU) and rational caudality (RCAU) are defined as:
\begin{center}
$DCAU = DE_{front} - DE_{post}$
$RCAU = \frac{DE_{front}}{DE_{post}}$
\end{center}

\npar

Another feature are the power fractions. These fractions give the power distribution for each channel and are defined as:
\begin{center}
$frac_{band,channel} = \frac{power_{band,channel}}{power_{total,channel}}$
\end{center}

\section{dataset} \label{dataset}
In this work the Dataset for Emotion Analysis using Physiological Signals (DEAP)\cite{DEAP} was used. This dataset consists of recordings of a physiological experiment. This experiment recorded emotional reactions of 32 subjects. The reactions were triggered using music video excerpts. Each subject watched 40 one-minute videos, while several physiological signals were recorded. These physiological signals consist of 32 channel, 512Hz EEG signals combined with the following peripheral signals:
\begin{itemize}
\item galvanic skin response (GSR), which measures perspiration
\item respiration belt, which measures the respiration rate
\item plethysmograph, which measures the blood pressure
\item skin temperature
\end{itemize}

\npar
%problem statement



\begin{table}[H]
\centering
\caption{An overview of the different features that were compared in this thesis.\label{featOverviewTable}}
\begin{tabular}{lllll}
\textbf{Name}           & \textbf{Type} & \textbf{no. Channels}   & \textbf{no. Frequency bands} & \textbf{Total} \\
\textbf{PSD}            & EEG           & 32                            & 6                         & 192          \\
\textbf{DE}             & eeg           & 32                            & 6                         & 192          \\
\textbf{DASM}           & eeg           & 13                            & 6                         & 78           \\
\textbf{RASM}           & eeg           & 13                            & 6                         & 78           \\
\textbf{DCAU}           & eeg           & 11                            & 6                         & 66           \\
\textbf{RCAU}           & eeg  & 11                            & 6                         & 66           \\
\textbf{Frac}           & eeg           & 32                            & 5                         & 160          \\
\textbf{Alpha / Beta}   & eeg           & 32                            & 1                         & 32           \\
\textbf{EEG Total}      &               &                               &                           & 864          \\
                        &               &                               &                           &              \\
\textbf{Name}           & \textbf{Type} & \textbf{no. Statistics} &                          &              \\
\textbf{HR}             & non-eeg       & 6                             &                           &              \\
\textbf{Plethysmograph} & non-eeg       & 6                             &                           &              \\
\textbf{GSR}            & non-eeg       & 6                             &                           &              \\
\textbf{ST}             & non-eeg       & 6                             &                           &              \\
\textbf{RSP}            & non-eeg       & 6                             &                           &              \\
\textbf{non-EEG Total}  &               & 30                            &                           &              \\
                        &               &                               &                           &              \\
\textbf{Overall Total}  & \textbf{894}  &                               &                           &             
\end{tabular}
\end{table}

%approach


%results

%conclusion


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

\begin{thebibliography}{1}

\bibitem{dey2000}
G.D.~Abowd, A.K.~Deyand P.J.~Brown, N.~Davies, M.~Smith and P.~Steggles.
\newblock Towards a Better Understanding of Context and Context-Awareness.
\newblock In {\em Proceedings of the 1st International Symposium on Handheld and Ubiquitous Computing (HUC),
	1999}, pages 304--307.

\end{thebibliography}

\end{document}



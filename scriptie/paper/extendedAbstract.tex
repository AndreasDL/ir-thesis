
%emotion recognition
Emotion recognition is the process of recognizing a person's emotion. Observing and recognizing emotion can be done in several ways. Psychology makes a clear distinction between physiological behaviour and a person's expression of emotion. The expression is often prone to social masking, the process of hiding emotion to conform to social standards and ideas, making it less reliable. The physiological behaviour on the other hand is much harder to control, making it more reliable. 

\npar

This work will focus on emotion recognition using physiological signals. Next the classification of emotion will be explained, before an introduction of basic machine learning techniques is given. What follows is an overview of the used features and the problem statement. This papers end with explaining the used approach, results and conclusion of this work.

\npar

Before emotion can be recognized, different emotions need to be defined. One way to do this is to use several distinct emotions, e.g. anger, joy, sad and pleasure. The advantage of this approach is that all emotions have a clear label. The disadvantage is that this model is often not complex enough to fully represent an emotion state. To solve this problem, the bipolar valence-arousal model was introduced. This model puts each emotion in a two dimensional space. The first dimension, ranges from inactive to active and indicates how active a person is feeling. The next dimension is valence. This dimension indicates how pleasant or unpleasant the emotion is perceived. 

\npar

The valence-arousal model has the advantage that an emotion can be defined, without needing to explicitly labelling it. Additionally, all discrete emotions can be mapped to the valence-arousal space. For example, excitement corresponds to an active feeling with a pleasant experience, meaning that is will be in the high valence, high arousal quadrant of the space. The mapping of other emotions can be done similarly and is shown in Figure \ref{ArousalValenceModel}.

\mijnfiguur{width=0.5\textwidth}{ArousalValenceModel}{The arousal - valence model maps emotions in a two dimensional plane\citep{ValArrFig}}

\npar

%machine learning
The emotion recognition will thus take some physiological signals as input and output a valence or arousal score. The 'processing' part is done using machine learning. In short, machine learning is an input output model that predicts output values for different samples based on the inputs. The inputs are features of the input samples, e.g. the frequency or amplitude of a signal.

\npar

%features
To do emotion recognition with machine learning, good features are required. This work focusses on physiological signals that can be split into two groups of features. The first group is are the peripheral signals, a.o. heart rate, blood pressure, respiration rate, perspiration, etc. 

\npar

The second group of features originate from the brain. These signals are recordings of brain activity using electroencephalography (EEG) %TODO gloss. 
EEG is a technique that measures electrical activity of the brain, by placing electrodes on the scalp. Even though EEG is very noisy by nature as the signal is distorted by the bone between the cortex and the electrodes it still provides significant insight in the brain activity. The electrodes are placed according to the 10/20 system, that labels each location. The locations and the corresponding channel names used in this work are visible in Figure \ref{1020labels}.

\mijnfiguur{width=0.7\textwidth}{1020labels}{Placement of the 32 electrodes in this thesis.}

EEG measures electrical activity at each channel. Each measurement can be split in different frequency bands, with medical relevance. The frequency bands are:
\begin{itemize}
\item \textbf{Alpha:} 8-13Hz, indicate how relaxed and/or inactive the brain is.
\item \textbf{Beta:} 13-30HZ, indicate a more active and focused state of mind.
\item \textbf{Gamma:} 30-50Hz, relate to simultaneous processing of information from different brain areas.
\item \textbf{Delta:} 0-4hz, these waves are generated during dreamless sleep and meditation.
\item \textbf{Theta:} 4-8Hz, occurs during dreaming.
\end{itemize}

%problem statement
\npar
In literature, a lot of features have been found. For the peripheral signals, statistical values of each channel are used. These statistical values are minimum, maximum, variation, standard deviation, average and median of each channel. 

\npar

The EEG features use a different approach, here the power spectral density (PSD) of each EEG signal is calculated. The PSD gives the distribution of the signal's energy in the frequency domain. Another power feature is the differential entropy (DE), which is defined as:
\begin{center}
$DE_{channel} = - \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi\sigma^2}} exp(\frac{(x-\mu)^2}{2\sigma^2}) log(\frac{1}{\sqrt{2\pi\sigma^2}}) exp(\frac{(x-\mu)^2}{2\sigma^2})dx$
\end{center}
It is proven that the differential entropy of a certain band is equivalent to the logarithmic power spectral density for a fixed length EEG sequence\citep{diffEnt}. This simplifies the calculations significantly.
\begin{center}
$DE_{channel} = log(PSD_{channel})$
\end{center}

\npar

The most used features for valence classification are asymmetry features that measure asymmetry between two channels. This can be done in two ways. The first way is the differential asymmetry (DASM) which is defined as:

\begin{center}
$DASM = DE_{left} - DE_{right}$
\end{center}

Another way to measure the asymmetry is by division. The Rational Asymmetry (RASM) \newacronym{RASM}{RASM}{Rational Asymmetry} does exactly this and is given by: \\

\begin{center}
$RASM = \frac{DE_{left}}{DE_{right}}$
\end{center}

\npar

The asymmetry features can also be used in the other direction. Instead of looking at the asymmetry between left and right, one can also compare the frontal power with the posterior power. This is known as the caudality. The differential caudality (DCAU) and rational caudality (RCAU) are defined as:
\begin{center}
$DCAU = DE_{front} - DE_{post}$
$RCAU = \frac{DE_{front}}{DE_{post}}$
\end{center}

\npar

Another feature are the power fractions. These fractions give the power distribution for each channel and are defined as:
\begin{center}
$frac_{band,channel} = \frac{power_{band,channel}}{power_{total,channel}}$
\end{center}

\npar

In this work the Dataset for Emotion Analysis using Physiological Signals (DEAP)\cite{DEAP} was used. This dataset consists of recordings of a physiological experiment. This experiment recorded emotional reactions of 32 subjects. The reactions were triggered using music video excerpts. Each subject watched 40 one-minute videos, while several physiological signals were recorded. These physiological signals consist of 32 channel, 512Hz EEG signals combined with the following peripheral signals:
\begin{itemize}
\item galvanic skin response (GSR), which measures perspiration
\item respiration belt, which measures the respiration rate
\item plethysmograph, which measures the blood pressure
\item skin temperature
\end{itemize}

\npar
%problem statement



\begin{table}[H]
\centering
\caption{An overview of the different features that were compared in this thesis.\label{featOverviewTable}}
\begin{tabular}{lllll}
\textbf{Name}           & \textbf{Type} & \textbf{no. Channels}   & \textbf{no. Frequency bands} & \textbf{Total} \\
\textbf{PSD}            & EEG           & 32                            & 6                         & 192          \\
\textbf{DE}             & eeg           & 32                            & 6                         & 192          \\
\textbf{DASM}           & eeg           & 13                            & 6                         & 78           \\
\textbf{RASM}           & eeg           & 13                            & 6                         & 78           \\
\textbf{DCAU}           & eeg           & 11                            & 6                         & 66           \\
\textbf{RCAU}           & eeg  & 11                            & 6                         & 66           \\
\textbf{Frac}           & eeg           & 32                            & 5                         & 160          \\
\textbf{Alpha / Beta}   & eeg           & 32                            & 1                         & 32           \\
\textbf{EEG Total}      &               &                               &                           & 864          \\
                        &               &                               &                           &              \\
\textbf{Name}           & \textbf{Type} & \textbf{no. Statistics} &                          &              \\
\textbf{HR}             & non-eeg       & 6                             &                           &              \\
\textbf{Plethysmograph} & non-eeg       & 6                             &                           &              \\
\textbf{GSR}            & non-eeg       & 6                             &                           &              \\
\textbf{ST}             & non-eeg       & 6                             &                           &              \\
\textbf{RSP}            & non-eeg       & 6                             &                           &              \\
\textbf{non-EEG Total}  &               & 30                            &                           &              \\
                        &               &                               &                           &              \\
\textbf{Overall Total}  & \textbf{894}  &                               &                           &             
\end{tabular}
\end{table}

%approach


%results

%conclusion